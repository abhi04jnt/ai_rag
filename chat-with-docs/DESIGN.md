# System Design Document

## Table of Contents
1. [System Overview](#system-overview)
2. [Architecture Diagram](#architecture-diagram)
3. [Component Details](#component-details)
4. [Data Flow](#data-flow)
5. [Sequence Diagrams](#sequence-diagrams)
6. [Storage Structure](#storage-structure)

---

## System Overview

**Chat With Your Docs** is a RAG (Retrieval-Augmented Generation) system that enables conversational querying over a collection of documents. The system combines semantic search, LLM-based query reformulation, and automatic document indexing to provide accurate, grounded answers with source citations.

### Core Capabilities
- Multi-format document ingestion (15+ formats)
- Incremental indexing with change detection
- Conversational context handling
- Image extraction and retrieval
- Table structure preservation
- Real-time file monitoring

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          USER / CLIENT                                   â”‚
â”‚                     (HTTP REST API Requests)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       FASTAPI SERVER                                     â”‚
â”‚                      (src/api/main.py)                                   â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Startup       â”‚  â”‚   /chat          â”‚  â”‚   /health          â”‚    â”‚
â”‚  â”‚   - Check Index â”‚  â”‚   Endpoint       â”‚  â”‚   Endpoint         â”‚    â”‚
â”‚  â”‚   - Init Chat   â”‚  â”‚   - Validate     â”‚  â”‚   - Status Check   â”‚    â”‚
â”‚  â”‚   - Start Watch â”‚  â”‚   - Process      â”‚  â”‚                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CHAT SERVICE                                        â”‚
â”‚                     (src/rag/chat.py)                                    â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Safety Filter (PII/PHI detection)                            â”‚  â”‚
â”‚  â”‚  2. Query Reformulation (LLM-based for follow-ups)               â”‚  â”‚
â”‚  â”‚  3. Visual Query Detection (diagram/chart/image keywords)        â”‚  â”‚
â”‚  â”‚  4. Embedding Generation (sentence-transformers)                 â”‚  â”‚
â”‚  â”‚  5. Vector Search (FAISS)                                        â”‚  â”‚
â”‚  â”‚  6. Image Prioritization (for visual queries)                    â”‚  â”‚
â”‚  â”‚  7. LLM Generation (OpenAI/Ollama)                               â”‚  â”‚
â”‚  â”‚  8. Response Formatting (answer + citations + images)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                         â”‚
              â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    EMBEDDER             â”‚   â”‚    LLM PROVIDER         â”‚
â”‚ (src/rag/embeddings.py) â”‚   â”‚   (src/rag/llm.py)      â”‚
â”‚                         â”‚   â”‚                         â”‚
â”‚  - Model Loading        â”‚   â”‚  - OpenAI Client        â”‚
â”‚  - Text Normalization   â”‚   â”‚  - Ollama Client        â”‚
â”‚  - Batch Processing     â”‚   â”‚  - Prompt Building      â”‚
â”‚  - Vector Generation    â”‚   â”‚  - Response Parsing     â”‚
â”‚    (384-dim)            â”‚   â”‚  - Error Handling       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     VECTOR STORE                                         â”‚
â”‚                  (src/rag/vectorstore.py)                                â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ FAISS Index  â”‚  â”‚ BM25 Index   â”‚  â”‚  Metadata    â”‚                 â”‚
â”‚  â”‚ (vectors)    â”‚  â”‚ (keywords)   â”‚  â”‚  (JSONL)     â”‚                 â”‚
â”‚  â”‚ 57MB         â”‚  â”‚ 6MB          â”‚  â”‚  102MB       â”‚                 â”‚
â”‚  â”‚ IndexFlatIP  â”‚  â”‚ Tokenized    â”‚  â”‚  text+images â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                           â”‚
â”‚  Operations:                                                             â”‚
â”‚  - search() - Pure vector or hybrid BM25+vector                         â”‚
â”‚  - add_documents() - Incremental addition                               â”‚
â”‚  - remove_document() - Delete and rebuild                               â”‚
â”‚  - needs_update() - Hash-based change detection                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–²
              â”‚
              â”‚ (reads/writes)
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       DISK STORAGE                                       â”‚
â”‚                     (data/index/)                                        â”‚
â”‚                                                                           â”‚
â”‚  ğŸ“„ faiss.index        - Vector database (FAISS binary format)          â”‚
â”‚  ğŸ“„ bm25.pkl           - BM25 tokenized corpus (pickle)                 â”‚
â”‚  ğŸ“„ metadata.jsonl     - Chunk metadata with images (JSON Lines)        â”‚
â”‚  ğŸ“„ doc_hashes.json    - File SHA256 hashes for change detection        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCUMENT INGESTION PIPELINE                           â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   Auto    â”‚â”€â”€â–¶â”‚  Ingest  â”‚â”€â”€â–¶â”‚ Loader  â”‚â”€â”€â–¶â”‚ Chunker  â”‚            â”‚
â”‚  â”‚  Indexer  â”‚   â”‚ Pipeline â”‚   â”‚         â”‚   â”‚          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â”‚              â”‚                â”‚              â”‚                   â”‚
â”‚       â”‚              â”‚                â”‚              â–¼                   â”‚
â”‚       â–¼              â”‚                â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                â”‚         â”‚ Embedder â”‚            â”‚
â”‚  â”‚ Watchdog  â”‚      â”‚                â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”‚  Monitor  â”‚      â”‚                â”‚              â”‚                   â”‚
â”‚  â”‚           â”‚      â”‚                â–¼              â–¼                   â”‚
â”‚  â”‚ Detects:  â”‚      â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ - Create  â”‚      â”‚         â”‚  Format-Specific Loaders â”‚            â”‚
â”‚  â”‚ - Modify  â”‚      â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚ - Delete  â”‚      â”‚         â”‚ PDF   â†’ pypdf + images   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚         â”‚ DOCX  â†’ python-docx      â”‚            â”‚
â”‚       â”‚              â”‚         â”‚ XLSX  â†’ openpyxl+tables  â”‚            â”‚
â”‚       â”‚              â”‚         â”‚ HTML  â†’ bs4+tables       â”‚            â”‚
â”‚       â”‚              â”‚         â”‚ CSV   â†’ csv+tables       â”‚            â”‚
â”‚       â–¼              â”‚         â”‚ TXT   â†’ encoding detect  â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”‚ Debounce  â”‚      â”‚                â”‚                                  â”‚
â”‚  â”‚  (2 sec)  â”‚      â”‚                â–¼                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚       â”‚              â”‚         â”‚ Text + Imagesâ”‚                         â”‚
â”‚       â”‚              â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚       â–¼              â”‚                â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                â–¼                                  â”‚
â”‚  â”‚  Trigger  â”‚â”€â”€â”€â”€â”€â”€â”˜         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚  Ingest   â”‚                â”‚  Chunking     â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  (1000 tokens)â”‚                         â”‚
â”‚                                â”‚  (200 overlap)â”‚                         â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                       â”‚                                  â”‚
â”‚                                       â–¼                                  â”‚
â”‚                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                                â”‚ Vector Store â”‚                         â”‚
â”‚                                â”‚   Update     â”‚                         â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA SOURCES                                    â”‚
â”‚                          (data/ folder)                                  â”‚
â”‚                                                                           â”‚
â”‚  ğŸ“ docs/                   - User documents (monitored)                â”‚
â”‚  ğŸ“ example-docs/           - Sample files (monitored)                  â”‚
â”‚  ğŸ“ index/                  - Generated index (excluded from watch)     â”‚
â”‚                                                                           â”‚
â”‚  Supported: PDF, DOCX, PPTX, XLSX, HTML, XML, EML, CSV, JSON, MD, TXT  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. FastAPI Server (`src/api/main.py`)

**Responsibilities:**
- HTTP endpoint management
- Request validation
- Startup initialization
- Auto-indexer lifecycle

**Key Functions:**
```python
@app.on_event("startup")
def _startup():
    # 1. Check if index exists
    # 2. Run initial indexing if missing
    # 3. Initialize ChatService
    # 4. Start AutoIndexer (file watcher)

@app.post("/chat")
async def chat(request: ChatRequest):
    # 1. Validate request
    # 2. Call chat_service.answer()
    # 3. Return ChatResponse
```

**Endpoints:**
| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/` | GET | Serve web UI |
| `/chat` | POST | Answer questions |
| `/health` | GET | Health check |

---

### 2. Chat Service (`src/rag/chat.py`)

**Responsibilities:**
- Query processing pipeline
- Safety filtering
- Query reformulation
- Retrieval coordination
- LLM answer generation

**Pipeline Flow:**
```
User Question
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Safety Filter   â”‚ â†’ Check for PII/PHI
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Reform.   â”‚ â†’ LLM reformulates follow-ups
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visual Detect   â”‚ â†’ Check for diagram/chart keywords
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding       â”‚ â†’ Convert to 384-dim vector
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector Search   â”‚ â†’ FAISS similarity search (pure semantic)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Image Priority  â”‚ â†’ Sort image chunks first (if visual query)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Generate    â”‚ â†’ GPT-4o-mini with context
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    Response
```

**Key Methods:**
```python
async def answer(question: str, history: list):
    # 1. safety_filter.check_content_safety(question)
    # 2. search_query = _reformulate_with_context(question, history)
    # 3. qvec = embedder.embed_texts([search_query])
    # 4. retrieved = store.search(qvec, top_k=5)
    # 5. text = llm.complete(prompt)
    # 6. return {answer, retrieved}

async def _reformulate_with_context(question: str, history: list):
    # Uses LLM to understand conversation context
    # Handles pronouns and references
```

---

### 3. Vector Store (`src/rag/vectorstore.py`)

**Responsibilities:**
- FAISS index management
- BM25 index management (optional)
- Metadata storage
- Incremental updates
- Change detection

**Data Structures:**
```python
class FaissStore:
    index: faiss.IndexFlatIP           # Vector index (inner product)
    bm25: BM25Okapi                    # Keyword index
    meta: list[dict]                   # Chunk metadata
    doc_hashes: dict[str, str]         # filename -> SHA256 hash
    tokenized_corpus: list[list[str]]  # For BM25
```

**Key Operations:**

**Search (Pure Vector - Default):**
```python
def _vector_search(query_vec, top_k):
    # 1. FAISS similarity search
    # 2. Deduplicate by source (keep latest)
    # 3. Sort by score descending
    # 4. Return top_k results
```

**Search (Hybrid - Optional):**
```python
def _hybrid_search(query_vec, query_text, top_k, bm25_weight):
    # 1. Get vector search results
    # 2. Get BM25 search results
    # 3. Reciprocal Rank Fusion (RRF)
    #    score = (1-w) * vector_score + w * bm25_score
    # 4. Deduplicate and sort
    # 5. Return top_k results
```

**Incremental Update:**
```python
def add_documents(vectors, chunks, file_hash):
    # 1. Add vectors to FAISS index
    # 2. Append to metadata list
    # 3. Update tokenized corpus
    # 4. Rebuild BM25 (fast operation)
    # 5. Store file hash
```

**Delete Document:**
```python
def remove_document(source):
    # 1. Find indices to keep
    # 2. Extract vectors from old index
    # 3. Create new FAISS index with filtered vectors
    # 4. Update metadata
    # 5. Rebuild BM25
```

---

### 4. Document Loader (`src/rag/unstructured_loader.py`)

**Responsibilities:**
- Multi-format parsing
- Text extraction
- Image extraction (PDF)
- Table preservation
- Encoding detection

**Format Handlers:**

| Format | Library | Special Handling |
|--------|---------|------------------|
| PDF | pypdf | Extract images from /XObject, filter <50x50px or >1MB |
| DOCX | python-docx | Extract paragraphs, preserve styles |
| XLSX | openpyxl | Convert to markdown tables, filter empty rows |
| HTML | BeautifulSoup4 | Convert `<table>` to markdown, remove scripts |
| CSV | csv module | Convert to markdown tables, detect delimiter |
| JSON | json module | Pretty print or flatten |
| TXT/MD | built-in | Detect encoding (UTF-8/16/32) |

**Table Extraction Example:**
```python
# HTML/Excel/CSV â†’ Markdown Table
Input:  <table><tr><th>Name</th><th>Age</th></tr>...</table>
Output: | Name | Age |
        | --- | --- |
        | John | 30 |
```

**Image Extraction (PDF):**
```python
def _extract_images(page):
    # 1. Access /Resources/XObject
    # 2. For each object:
    #    - Check if it's an image
    #    - Filter by size (50x50 < size < 1MB)
    #    - Extract bytes
    #    - Base64 encode
    #    - Store metadata (page, format, dimensions)
```

---

### 5. Embedder (`src/rag/embeddings.py`)

**Responsibilities:**
- Model loading (sentence-transformers)
- Text embedding generation
- Batch processing
- Vector normalization

**Implementation:**
```python
class Embedder:
    def __init__(self, model_name):
        self.model = SentenceTransformer(model_name)
        # all-MiniLM-L6-v2: 384-dim, 80MB, ~50ms/query
    
    def embed_texts(self, texts: list[str]) -> np.ndarray:
        # 1. Batch processing (up to 32 at once)
        # 2. Model inference
        # 3. Normalize vectors (for cosine similarity)
        # 4. Return numpy array (N x 384)
```

**Normalization:**
- Vectors are L2-normalized for cosine similarity
- FAISS IndexFlatIP uses inner product (equivalent to cosine for normalized vectors)

---

### 6. LLM Provider (`src/rag/llm.py`)

**Responsibilities:**
- LLM client management
- Prompt construction
- API communication
- Response parsing

**Providers:**

**OpenAI:**
```python
class OpenAILLM:
    async def complete(self, prompt: str) -> str:
        # 1. Construct messages [system, user]
        # 2. Call OpenAI API
        # 3. Parse response
        # 4. Handle rate limits/errors
```

**Ollama (Local):**
```python
class OllamaLLM:
    async def complete(self, prompt: str) -> str:
        # 1. HTTP request to localhost:11434
        # 2. Stream or batch response
        # 3. Parse JSON
```

---

### 7. Auto Indexer (`src/rag/auto_indexer.py`)

**Responsibilities:**
- File system monitoring
- Change detection
- Automatic re-indexing
- Event debouncing

**Implementation:**
```python
class AutoIndexer:
    def __init__(self, docs_dir, store, embedder, index_dir):
        self.observer = Observer()  # watchdog
        self.handler = FileChangeHandler()
    
    def start():
        # Start watchdog observer
        # Watch docs_dir recursively
        # Exclude index_dir
    
    def on_created(event):
        # Wait 2 seconds (debounce)
        # Load document
        # Generate embeddings
        # store.add_documents()
    
    def on_modified(event):
        # Remove old version
        # Add new version
    
    def on_deleted(event):
        # store.remove_document()
```

**Debouncing:**
- Waits 2 seconds after file write completes
- Prevents multiple triggers for same file
- Uses threading.Timer

---

### 8. Chunking (`src/rag/chunking.py`)

**Responsibilities:**
- Text splitting
- Overlap management
- Chunk metadata

**Strategy:**
```python
CHUNK_SIZE = 1000   # tokens
CHUNK_OVERLAP = 200 # tokens

def chunk_text(text, source, images):
    # 1. Tokenize with tiktoken
    # 2. Split into chunks of CHUNK_SIZE
    # 3. Add CHUNK_OVERLAP between chunks
    # 4. Associate images with first chunk
    # 5. Return list of Chunk objects
```

**Chunk Object:**
```python
@dataclass
class Chunk:
    source: str          # Filename
    chunk_id: int        # 0, 1, 2, ...
    text: str            # Chunk text
    timestamp: float     # Unix timestamp
    images: list[dict]   # [{"page": 1, "format": "PNG", "data": "base64..."}]
```

---

### 9. Configuration (`src/rag/config.py`)

**Responsibilities:**
- Environment variable loading
- Default values
- Path resolution

**Settings:**
```python
class Settings:
    docs_dir: str = "./data"
    index_dir: str = "./data/index"
    embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"
    openai_model: str = "gpt-4o-mini"
    top_k: int = 5
    
settings = Settings()
```

---

## Data Flow

### 1. Document Ingestion Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Add File   â”‚
â”‚ to data/    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Watchdog   â”‚â”€â”€â”€â”
â”‚  Detects    â”‚   â”‚ (debounce 2s)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Compute    â”‚  â”‚
â”‚  SHA256     â”‚  â”‚
â”‚  Hash       â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Check      â”‚  â”‚
â”‚  if Changed â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Load       â”‚  â”‚
â”‚  Document   â”‚  â”‚
â”‚  (format-   â”‚  â”‚
â”‚   specific) â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Extract    â”‚  â”‚
â”‚  - Text     â”‚  â”‚
â”‚  - Images   â”‚  â”‚
â”‚  - Tables   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Chunk      â”‚  â”‚
â”‚  (1000 tok, â”‚  â”‚
â”‚   200 over) â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Generate   â”‚  â”‚
â”‚  Embeddings â”‚  â”‚
â”‚  (384-dim)  â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Add to     â”‚  â”‚
â”‚  FAISS      â”‚  â”‚
â”‚  Index      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Update     â”‚  â”‚
â”‚  Metadata   â”‚  â”‚
â”‚  & Hashes   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚          â”‚
       â–¼          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  Save to    â”‚â—€â”€â”˜
â”‚  Disk       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Query Processing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Safety      â”‚â”€â”€â†’ Reject if PII/PHI detected
â”‚ Filter      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check for   â”‚
â”‚ Follow-up   â”‚
â”‚ (history    â”‚
â”‚  length>0)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€ Yes â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚            â”‚ Reformulate  â”‚
       â”‚            â”‚ with LLM     â”‚
       â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â–¼                   â–¼
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Visual Query?    â”‚
       â”‚ (diagram/chart)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Yes          No     â”‚
       â”‚ top_k*2      top_k  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Generate         â”‚
       â”‚ Embedding        â”‚
       â”‚ (384-dim vector) â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Vector Search    â”‚
       â”‚ (FAISS)          â”‚
       â”‚ Pure Semantic    â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Deduplicate      â”‚
       â”‚ by Source        â”‚
       â”‚ (keep latest)    â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Visual Query?    â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Yes          No     â”‚
       â”‚ Prioritize   Keep   â”‚
       â”‚ img chunks   order  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Build Context    â”‚
       â”‚ from Retrieved   â”‚
       â”‚ Chunks           â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Build Prompt     â”‚
       â”‚ - System         â”‚
       â”‚ - Context        â”‚
       â”‚ - History        â”‚
       â”‚ - Question       â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ LLM Generate     â”‚
       â”‚ (GPT-4o-mini)    â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Format Response  â”‚
       â”‚ - Answer         â”‚
       â”‚ - Citations      â”‚
       â”‚ - Images         â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Return to User   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Sequence Diagrams

### 1. Initial Startup Sequence

```
User                FastAPI             ChatService         VectorStore         FileSystem
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚â”€â”€uvicorn startâ”€â”€â”€â”€â–¶â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚â”€â”€check indexâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚â—€â”€â”€exists?â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚â—€â”€index missingâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚â”€â”€run_ingest()â”€â”€â”€â”€â”€â”€â”€â–¶                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚â”€â”€scan docsâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚â—€â”€file listâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚â”€â”€load+embedâ”€â”€â”€â”€â”€â”€â”€â–¶                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚â”€â”€build indexâ”€â”€â”€â”€â”€â”€â–¶                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚â”€â”€saveâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚â—€â”€completeâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚â”€â”€init ChatServiceâ”€â”€â–¶â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚â”€â”€load indexâ”€â”€â”€â”€â”€â”€â”€â–¶                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚â—€â”€service readyâ”€â”€â”€â”€â”€â”€â”‚                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚                    â”‚â”€â”€start watcherâ”€â”€â”€â”€â”€â”€â–¶                   â”‚                   â”‚
 â”‚                    â”‚                     â”‚                   â”‚                   â”‚
 â”‚â—€â”€server readyâ”€â”€â”€â”€â”€â”€â”‚                     â”‚                   â”‚                   â”‚
```

### 2. Chat Query Sequence

```
User         FastAPI      ChatService    SafetyFilter   Embedder    VectorStore    LLM
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚â”€â”€/chat POSTâ”€â–¶â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚â”€â”€answer()â”€â”€â–¶â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â”€â”€check_safetyâ–¶â”‚            â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â—€â”€safeâ”€â”€â”€â”€â”€â”€â”€â”€â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â”€â”€reformulate (if follow-up)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â—€â”€reformulated queryâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â”€â”€embedâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â—€â”€vectorâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â”€â”€searchâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â—€â”€top_k chunksâ”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â”€â”€build promptâ”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚â—€â”€answerâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚â—€â”€responseâ”€â”€â”€â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚              â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
 â”‚â—€â”€JSON respâ”€â”€â”€â”‚             â”‚              â”‚             â”‚            â”‚            â”‚
```

### 3. File Change Detection Sequence

```
FileSystem     AutoIndexer    Ingest      Loader     Embedder    VectorStore
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚â”€â”€file addedâ”€â”€â–¶â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚â”€â”€debounceâ”€â”€â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚  (2 sec)   â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚â”€â”€hash fileâ”€â–¶â”‚          â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â”€â”€checkâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
    â”‚               â”‚            â”‚  exists?  â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â—€â”€new fileâ”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â”€â”€loadâ”€â”€â”€â”€â”€â–¶â”‚          â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â—€â”€text+imgâ”€â”€â”‚          â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â”€â”€chunkâ”€â”€â”€â”€â–¶â”‚          â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â”€â”€embedâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â—€â”€vectorsâ”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â”€â”€add docsâ”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚            â”‚â”€â”€saveâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
    â”‚               â”‚            â”‚           â”‚           â”‚            â”‚
    â”‚               â”‚â—€â”€completeâ”€â”€â”‚           â”‚           â”‚            â”‚
```

---

## Storage Structure

### Directory Layout

```
chat-with-docs/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ docs/                    # User documents (watched)
â”‚   â”‚   â”œâ”€â”€ report.pdf
â”‚   â”‚   â”œâ”€â”€ spreadsheet.xlsx
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ example-docs/            # Sample files (watched)
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ index/                   # Generated indices (excluded from watch)
â”‚       â”œâ”€â”€ faiss.index          # FAISS vector database
â”‚       â”œâ”€â”€ bm25.pkl             # BM25 tokenized corpus
â”‚       â”œâ”€â”€ metadata.jsonl       # Chunk metadata with images
â”‚       â””â”€â”€ doc_hashes.json      # File change tracking
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py              # FastAPI application
â”‚   â”‚
â”‚   â””â”€â”€ rag/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ auto_indexer.py      # File watcher
â”‚       â”œâ”€â”€ chat.py              # Query processing
â”‚       â”œâ”€â”€ chunking.py          # Text splitting
â”‚       â”œâ”€â”€ config.py            # Settings
â”‚       â”œâ”€â”€ embeddings.py        # Embedding generation
â”‚       â”œâ”€â”€ ingest.py            # Indexing pipeline
â”‚       â”œâ”€â”€ llm.py               # LLM providers
â”‚       â”œâ”€â”€ prompts.py           # System prompts
â”‚       â”œâ”€â”€ unstructured_loader.py  # Document loaders
â”‚       â””â”€â”€ vectorstore.py       # FAISS + BM25 management
â”‚
â”œâ”€â”€ .env                         # Configuration
â”œâ”€â”€ pyproject.toml               # Dependencies
â””â”€â”€ README.md                    # Documentation
```

### Index File Formats

**1. faiss.index (Binary)**
```
Format: FAISS IndexFlatIP binary format
Size: 57MB for 38,863 vectors (384 dimensions)
Structure:
  - Header (index type, dimension)
  - Vector data (float32, L2-normalized)
  - Optimized for inner product search
```

**2. bm25.pkl (Pickle)**
```python
{
    "tokenized_corpus": [
        ["word1", "word2", ...],  # Document 0
        ["word3", "word4", ...],  # Document 1
        ...
    ]
}
# BM25Okapi object reconstructed from this
```

**3. metadata.jsonl (JSON Lines)**
```json
{"id": 0, "source": "doc.pdf", "chunk_id": 0, "text": "...", "timestamp": 1707123456.789, "images": [...]}
{"id": 1, "source": "doc.pdf", "chunk_id": 1, "text": "...", "timestamp": 1707123456.789, "images": []}
...
```

**4. doc_hashes.json (JSON)**
```json
{
  "document1.pdf": "a1b2c3d4e5f6...",
  "spreadsheet.xlsx": "f6e5d4c3b2a1...",
  ...
}
```

### Metadata Schema

**Chunk Metadata:**
```json
{
  "id": 42,
  "source": "building-blocks-of-rag.pdf",
  "chunk_id": 15,
  "text": "Retrieval-Augmented Generation (RAG) is...",
  "timestamp": 1707123456.789,
  "images": [
    {
      "page": 3,
      "format": "PNG",
      "width": 800,
      "height": 600,
      "data": "iVBORw0KGgoAAAANSUhEUgAA..."
    }
  ]
}
```

**Image Metadata:**
```json
{
  "page": 3,
  "format": "PNG",
  "width": 800,
  "height": 600,
  "data": "base64_encoded_image_bytes"
}
```

---

## Key Algorithms

### 1. Reciprocal Rank Fusion (RRF)

**Purpose:** Combine BM25 and vector search scores

```python
def reciprocal_rank_fusion(vector_ranks, bm25_ranks, k=60, weight=0.15):
    """
    RRF Score = (1-w) * (1/(k + vector_rank)) + w * (1/(k + bm25_rank))
    
    Args:
        vector_ranks: {doc_id: rank} from vector search
        bm25_ranks: {doc_id: rank} from BM25 search
        k: RRF constant (default 60)
        weight: BM25 weight (0-1, default 0.15)
    
    Returns:
        Sorted list of (doc_id, score) tuples
    """
    all_docs = set(vector_ranks.keys()) | set(bm25_ranks.keys())
    scores = {}
    
    for doc_id in all_docs:
        v_score = 1 / (k + vector_ranks.get(doc_id, 1000)) if doc_id in vector_ranks else 0
        b_score = 1 / (k + bm25_ranks.get(doc_id, 1000)) if doc_id in bm25_ranks else 0
        scores[doc_id] = (1 - weight) * v_score + weight * b_score
    
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

### 2. Incremental Index Update

**Purpose:** Only re-index changed files

```python
def incremental_update(new_file_path, old_hash, new_hash):
    """
    1. Compare hashes
    2. If changed:
       a. Remove old vectors (rebuild FAISS)
       b. Load new document
       c. Generate embeddings
       d. Add to FAISS
       e. Update metadata
       f. Save index
    """
    if old_hash != new_hash:
        # File changed
        store.remove_document(filename)
        text, images = loader.load_document(new_file_path)
        chunks = chunk_text(text, filename, images)
        vectors = embedder.embed_texts([c.text for c in chunks])
        store.add_documents(vectors, chunks, new_hash)
        store.save()
```

### 3. Query Reformulation

**Purpose:** Handle follow-up questions with context

```python
async def reformulate_with_context(question, history):
    """
    Use LLM to reformulate question based on conversation history
    
    Example:
    History: 
      User: "What is RAG?"
      Assistant: "RAG is Retrieval-Augmented Generation..."
    
    Question: "Show me the architecture diagram"
    
    Reformulated: "Show me the RAG architecture diagram"
    """
    prompt = f"""
    Given conversation history, reformulate the question to be standalone.
    
    History: {history}
    Question: {question}
    
    Reformulated question:
    """
    
    return await llm.complete(prompt)
```

---

## Performance Characteristics

### Time Complexity

| Operation | Complexity | Notes |
|-----------|------------|-------|
| Embedding generation | O(n) | n = text length, ~50ms per query |
| FAISS search | O(log n) | n = index size, <100ms for 40K vectors |
| BM25 search | O(n) | n = corpus size, ~20ms for 40K docs |
| LLM generation | O(1) | Network-bound, ~1-2s |
| Index build | O(nÂ·d) | n = docs, d = avg doc size |
| Incremental add | O(k) | k = new doc chunks, ~2-5s |

### Space Complexity

| Component | Size | Scaling |
|-----------|------|---------|
| FAISS index | 57MB | O(nÂ·d), d=384 dims |
| BM25 corpus | 6MB | O(nÂ·v), v=vocab size |
| Metadata | 102MB | O(nÂ·t+i), t=text, i=images |
| Total | 165MB | For 38,863 chunks |

---

## Configuration & Tuning

### Key Parameters

```python
# Embedding
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_DIM = 384

# Chunking
CHUNK_SIZE = 1000   # tokens
CHUNK_OVERLAP = 200 # tokens

# Retrieval
TOP_K = 5
VISUAL_QUERY_MULTIPLIER = 2  # top_k * 2 for diagram queries

# Hybrid Search (if enabled)
BM25_WEIGHT = 0.15  # 15% BM25, 85% vector
RRF_K = 60          # RRF constant

# LLM
OPENAI_MODEL = "gpt-4o-mini"
TEMPERATURE = 0.0   # Deterministic

# Auto-indexer
DEBOUNCE_SECONDS = 2
```

### Tuning Guidelines

**For better semantic search:**
- Increase embedding dimension (use text-embedding-3-large)
- Reduce chunk size for granular retrieval
- Increase TOP_K for more context

**For better keyword matching:**
- Enable hybrid search (set `hybrid=True`)
- Increase BM25_WEIGHT (0.3-0.5)
- Use better tokenization (stemming)

**For faster indexing:**
- Increase CHUNK_SIZE (reduce total chunks)
- Use smaller embedding model
- Disable BM25 index

**For better answers:**
- Increase TOP_K (more context)
- Use GPT-4 instead of GPT-4o-mini
- Improve chunking (structure-aware)

---

## Error Handling

### Startup Errors

```python
try:
    # Check index exists
    if not index_exists():
        run_ingest(reset=True)
    
    chat_service = ChatService()
    auto_indexer = AutoIndexer()
    auto_indexer.start()
    
except Exception as e:
    logger.error(f"Startup failed: {e}")
    raise  # FastAPI will exit
```

### Query Errors

```python
try:
    # Safety check
    is_safe, reason = safety_filter.check(question)
    if not is_safe:
        raise RuntimeError(reason)
    
    # Search
    retrieved = store.search(qvec, top_k)
    
    if not retrieved:
        return {"answer": "No relevant documents found"}
    
    # LLM generation
    answer = await llm.complete(prompt)
    
except RuntimeError as e:
    # User-facing error
    raise HTTPException(status_code=400, detail=str(e))

except Exception as e:
    # Internal error
    logger.error(f"Query failed: {e}", exc_info=True)
    raise HTTPException(status_code=500, detail="Internal error")
```

### Indexing Errors

```python
def process_file(path):
    try:
        text, images = loader.load_document(path)
        
        if not text:
            logger.warning(f"Empty document: {path}")
            return
        
        chunks = chunk_text(text, path.name, images)
        vectors = embedder.embed_texts([c.text for c in chunks])
        store.add_documents(vectors, chunks, file_hash)
        
    except Exception as e:
        logger.error(f"Failed to process {path}: {e}")
        # Continue with next file (don't crash)
```

---

## Testing Strategy

### Unit Tests

```python
# Test individual components
test_embedder()          # Embedding generation
test_vectorstore()       # FAISS operations
test_loader()            # Document loading
test_chunking()          # Text splitting
test_reformulation()     # Query processing
```

### Integration Tests

```python
# Test component interactions
test_ingest_pipeline()   # Load â†’ Chunk â†’ Embed â†’ Index
test_search_pipeline()   # Query â†’ Embed â†’ Search â†’ Rank
test_chat_pipeline()     # Question â†’ Search â†’ LLM â†’ Answer
```

### End-to-End Tests

```python
# Test full system
test_add_document()      # Add file â†’ Auto-index â†’ Query
test_update_document()   # Modify file â†’ Re-index â†’ Query
test_delete_document()   # Delete file â†’ Remove from index
test_conversation()      # Multi-turn Q&A with context
```

---

## Deployment Considerations

### Production Checklist

- [ ] Set strong `OPENAI_API_KEY`
- [ ] Configure logging (file + rotation)
- [ ] Set up monitoring (Prometheus/Grafana)
- [ ] Enable HTTPS (reverse proxy)
- [ ] Set rate limits
- [ ] Configure CORS appropriately
- [ ] Set up backup for `data/index/`
- [ ] Monitor disk space (index grows)
- [ ] Set resource limits (memory, CPU)
- [ ] Configure error alerting

### Scaling

**Vertical Scaling (Single Server):**
- Increase RAM for larger indices
- Use GPU for faster embeddings
- SSD for faster I/O

**Horizontal Scaling (Multiple Servers):**
- Separate indexing and query servers
- Use shared storage (NFS/S3) for index
- Load balance query API
- Distributed FAISS (faiss-gpu, IVF index)

---

## Maintenance

### Regular Tasks

**Daily:**
- Monitor index size growth
- Check error logs
- Verify auto-indexer running

**Weekly:**
- Review slow queries
- Check disk space
- Update dependencies

**Monthly:**
- Optimize index (rebuild if fragmented)
- Evaluate retrieval quality
- Update embedding model if needed

### Troubleshooting

**Problem: Slow queries**
- Check index size (>100K chunks?)
- Profile with logging
- Consider IVF index for large scale

**Problem: Poor retrieval**
- Check chunk size (too large?)
- Verify embedding quality
- Test with different queries
- Try enabling hybrid search

**Problem: Out of memory**
- Reduce batch size in embedder
- Increase swap space
- Use smaller embedding model

---

## Future Enhancements

### Planned Improvements

1. **Multi-modal Embeddings (CLIP)**
   - Joint text-image search
   - Better visual query matching

2. **Query Expansion**
   - Automatic synonym generation
   - Related term injection

3. **Reranking**
   - Cross-encoder for top-k refinement
   - Improves precision

4. **Streaming Responses**
   - Server-Sent Events (SSE)
   - Real-time answer generation

5. **Evaluation Suite**
   - Automated quality metrics
   - Regression testing

---

## References

### Papers & Resources

- **RAG**: Lewis et al. "Retrieval-Augmented Generation" (2020)
- **BM25**: Robertson & Zaragoza "The Probabilistic Relevance Framework: BM25 and Beyond" (2009)
- **RRF**: Cormack et al. "Reciprocal Rank Fusion" (2009)
- **FAISS**: Johnson et al. "Billion-scale similarity search with GPUs" (2017)
- **Sentence Transformers**: Reimers & Gurevych "Sentence-BERT" (2019)

### Libraries

- FastAPI: https://fastapi.tiangolo.com/
- FAISS: https://github.com/facebookresearch/faiss
- Sentence Transformers: https://www.sbert.net/
- rank-bm25: https://github.com/dorianbrown/rank_bm25
- watchdog: https://github.com/gorakhargosh/watchdog

---

**Last Updated:** 2026-02-05
**Version:** 0.2.0
**Author:** System Design Documentation
